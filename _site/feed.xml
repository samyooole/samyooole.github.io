<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-08-04T16:29:44+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Samuel Ho</title><subtitle>Building bespoke tech solutions for the public good üå±</subtitle><entry><title type="html">Apart, an extremely detailed political map of North Carolina</title><link href="http://localhost:4000/blog/jekyll/2024/08/03/apart.html" rel="alternate" type="text/html" title="Apart, an extremely detailed political map of North Carolina" /><published>2024-08-03T09:00:00+08:00</published><updated>2024-08-03T09:00:00+08:00</updated><id>http://localhost:4000/blog/jekyll/2024/08/03/apart</id><content type="html" xml:base="http://localhost:4000/blog/jekyll/2024/08/03/apart.html"><![CDATA[<p>When doing my senior thesis in Economics, I discovered a treasure trove of data. The North Carolina State Board of Elections maintains a <a href="https://www.ncsbe.gov/results-data/voter-registration-data">record</a> of public use, individual-level voter registration data for the past 15 years. Each individual is uniquely identified, characterized demographically, and located via home address. After geo-coding these home addresses, I was able to get the rooftop-level location of every single registered voter in North Carolina.</p>

<p>I then decided to develop a web app which would allow you to visualize where residents of different parties were staying, at different levels of detail. Enter‚Ä¶ <strong>apart</strong>!</p>

<p><img src="/assets/apart_closeup.png" alt="" />
<em>A residential neighborhood in Statesville, North Carolina</em></p>

<p>See the residential location of every single registered voter in North Carolina in 2020 - red for Republican, blue for Democrat, grey for unaffiliated.</p>

<p><img src="/assets/apart_afar.png" alt="" /></p>

<p>At larger zoom levels, see aggregations of Democrats vs Republicans on a broad scale. The redder the area, the more densely populated the area is by Republicans as compared to Democrats. The same is true for the Democrats if the area is bluer. Purple areas are therefore areas with a more even balance between Democrat and Republican residents.</p>

<h2 id="architecture">Architecture</h2>
<p><img src="/assets/apart_codearchi.png" alt="" /></p>

<p>I use ReactJS for the front-end, with react-leaflet as the map framework. Huge kudos to the team maintaining react-leaflet and the OpenStreetMap contributors behind the map tiles, it is truly a grand undertaking and it is amazing that it is open source and available for free. On broad zoom levels (&lt;16), summary map tiles (pre-rendered using a Python script) are loaded. On the smaller zoom levels, the bounds of the map view are used to send an API request to a simple NodeJS backend server for the relevant individual locations of party affiliates. The server then queries a MySQL database instance, delivering the records back to the ReactJS frontend, which then parses the fields and serves them as dots in various colors. Each of these will have to be deployed on dedicated servers, with the front-end on Vercel and the back-end (NodeJS + MySQL) on a VPS. The NodeJS server is run locally, and is then exposed via nginx to the public as an API.</p>

<p>Try apart <a href="https://apart-react.vercel.app">here</a>!</p>]]></content><author><name></name></author><category term="blog" /><category term="jekyll" /><summary type="html"><![CDATA[When doing my senior thesis in Economics, I discovered a treasure trove of data. The North Carolina State Board of Elections maintains a record of public use, individual-level voter registration data for the past 15 years. Each individual is uniquely identified, characterized demographically, and located via home address. After geo-coding these home addresses, I was able to get the rooftop-level location of every single registered voter in North Carolina.]]></summary></entry><entry><title type="html">ùÑûwatch, a chord detector that runs on Chrome</title><link href="http://localhost:4000/blog/jekyll/2024/07/18/swatch.html" rel="alternate" type="text/html" title="ùÑûwatch, a chord detector that runs on Chrome" /><published>2024-07-18T10:00:00+08:00</published><updated>2024-07-18T10:00:00+08:00</updated><id>http://localhost:4000/blog/jekyll/2024/07/18/swatch</id><content type="html" xml:base="http://localhost:4000/blog/jekyll/2024/07/18/swatch.html"><![CDATA[<p>As a musician, finding the chords for a song is something I do <em>extremely</em> often. Whether I‚Äôm arranging for acappella or simply replicating the backbone of a pop song on the piano, knowing the chords of a song are crucial for capturing its essential colour - and provides a contextual springboard from which more musical fun can happen: reharmonizations, new melody lines, mashups, and more!</p>

<p>Most times, you‚Äôll be able to find the chords for the song you want online on a website like <a href="https://www.ultimate-guitar.com">Ultimate Guitar</a>. But these chords tend to come with a set of issues - maybe they are simplified, or they weren‚Äôt transcribed accurately. Sometimes, there‚Äôs a song that doesn‚Äôt have any transcription at all because it‚Äôs simply not well-known enough!</p>

<p>In those moments, I wished there was a convenient tool to help me detect chords instantaneously. That is what spurred me to build <strong>ùÑûwatch</strong>, a Chrome extension that detects chords. It follows in the great tradition of lightweight Chrome extensions like <a href="https://www.colorzilla.com/chrome/">Colorzilla</a> and <a href="https://transpose.video">Transpose</a>, both effective semi-automated tech solutions which automate away the non-essential, thereby allowing the user to exercise their expert judgement. I wanted my extension to be able to instantaneously capture the key of a song, just as Colorzilla could capture the hex code of a colour. I also wanted my extension to perform digital signal processing natively within Chrome, much like Transpose could perform key changes on music on the fly.</p>

<p>Introducing‚Ä¶ <strong>ùÑûwatch!</strong></p>

<p><img src="/assets/swatch_atlast_demo.gif" alt="" />
<em><a href="https://www.youtube.com/watch?v=HUwhPN5-9bk">At Last</a>, originally by Etta James, performed by Cynthia Erivo</em></p>

<p>Play music from any audio source on a browser tab, and ùÑûwatch will near-instantaneously detect the musical chord for you, whilst also displaying the relevant notes that belong to that chord, so you can easily replicate it! For example, if C Major is detected, then C, E, and G will appear on the on-screen digital piano. Finally, you can also play and pause from within the Chrome extension, avoiding the need to exit the extension view every time you need to pause/play.</p>

<h2 id="architecture">Architecture</h2>

<p><img src="/assets/swatch_codearchi.png" alt="" /></p>

<p>This app was served to the user as a Chrome extension, which by construction uses HTML and CSS for the front-end design, while using Javascript for back-end scripting. Because one of my goals was to optimize the audio digital signal processing in a lower level language (in summary, I perform Fast Fourier Transforms, bin frequencies into <a href="https://en.wikipedia.org/wiki/Chroma_feature">chroma</a>, before minimizing similarity to established chord-chroma profiles) - I coded all the backend processing in C++. However, because C++ would traditionally be run in an executable file, I use <a href="https://webassembly.org">WebAssembly</a> to transpile C++ into browser-readable assembly code. The Javascript backend calls the .wasm code for compute-intensive tasks, while maintaining the broader averaging functionalities needed to assert more stability in chord detection.</p>

<p>The happy result of choosing this architecture is: firstly, there is minimal installation required. Once the extension has been downloaded and installed into one‚Äôs browser from the Chrome Web Store (and it is a tiny program), there is no further configuration required. Secondly, the extension functions standalone, that is to say it does not need to ping a server to get audio processing results. This is great because we don‚Äôt need to spend resources on maintaining a dedicated server, and we are also saving on latency costs, assuming that every user‚Äôs computer and Chrome browser is competent enough to execute the .wasm code produced. Thirdly, chord detection happens live and near-instantaneously. Because the underlying C++ is so speedy, there is no need to do any patch-up work on the backend with respect to time alignments, and musicians can get what they need immediately, which is crucial for their workflows. No one wants to be bogged down at the boring, grindy work - we want to give them as much time as possible for the real creative work.</p>

<h2 id="conclusion">Conclusion</h2>

<p>There‚Äôs still a lot of work to be done on the DSP front when it comes to more precisely extracting chords. Clear-cut chords are easily identified correctly, but real songs with complicated chords are a much harder task that my extension does not yet excel at. Version 0.1 will soon be available on the Chrome Web Store for free.</p>]]></content><author><name></name></author><category term="blog" /><category term="jekyll" /><summary type="html"><![CDATA[As a musician, finding the chords for a song is something I do extremely often. Whether I‚Äôm arranging for acappella or simply replicating the backbone of a pop song on the piano, knowing the chords of a song are crucial for capturing its essential colour - and provides a contextual springboard from which more musical fun can happen: reharmonizations, new melody lines, mashups, and more!]]></summary></entry><entry><title type="html">Instabus, a customizable bus app for Singapore</title><link href="http://localhost:4000/blog/jekyll/2024/07/17/instabus.html" rel="alternate" type="text/html" title="Instabus, a customizable bus app for Singapore" /><published>2024-07-17T18:00:00+08:00</published><updated>2024-07-17T18:00:00+08:00</updated><id>http://localhost:4000/blog/jekyll/2024/07/17/instabus</id><content type="html" xml:base="http://localhost:4000/blog/jekyll/2024/07/17/instabus.html"><![CDATA[<p>Singapore has <em>excellent</em> public transport, but sometimes too much of a good thing can create a few relatively bad options. What do I mean?</p>

<p>While Singapore‚Äôs bus system is extensive, I am rather unfortunate to be living smack in the middle of a town block, something like this:</p>

<p><img src="/assets/idontlivehere.png" alt="" />
<em>I don‚Äôt actually live here, but let‚Äôs pretend I do</em></p>

<p>As you can see from this map, there are a healthy smattering of buses at different bus stops about equidistant from where I live, at the red x! The good thing about living here is I have plenty of options for the first/last mile of my journey. But give me 20 years of living in a place like this and one big problem starts to loom - which bus stop should I choose? Do I always go to the same bus stop and hopefully minimize my waiting time? Do I try to rifle through my bus app, with only one favourites tab with all the bus stops I care about, including all the buses I don‚Äôt care about?</p>

<p>This became enough of a frustration for me last summer that I set out to code an iOS app with a simple, central function: the <strong>movelist</strong>. Much like Spotify‚Äôs or Apple Music‚Äôs <em>play</em>list, you can gather the specific buses from different bus stops within the same grouping (eg. ‚Äúgoing to work‚Äù, ‚Äúcoming home from bus interchange‚Äù). This way, you are always only one tap away from seeing all the information you need to make a quick decision about which bus you should take in any given situation!</p>

<p>Enter‚Ä¶ Instabus!</p>

<div align="center">
    <img src="/assets/instabus_open_busstop.gif" width="300" />
</div>

<p>Much like any bus app out there, all the nearest bus stops are sorted by distance for easy access. Click the bus stop icon to reveal the available bus services and their next 3 bus arrival timings, color coded by the level of congestion within the bus (data is pulled from the <a href="https://datamall.lta.gov.sg/content/dam/datamall/datasets/LTA_DataMall_API_User_Guide.pdf">LTA DataMall API</a>).</p>

<div align="center">
    <img src="/assets/instabus_createmovelist.gif" width="300" />
</div>

<p>To create a movelist, simply press the + button on any bus you‚Äôre interested in adding to the movelist - it will bring you to a landing page where you can choose to create a movelist and give it a special name! Conveniently, if you‚Äôve already taken a particular name, it will simply add that bus to that relevant movelist.</p>

<div align="center">
    <img src="/assets/instabus_addmovelist.gif" width="300" />
</div>

<p>Adding buses to a movelist is also simple once you have already created movelists!</p>

<div align="center">
    <img src="/assets/instabus_movelistscreen.gif" width="300" />
</div>

<p>Once you have all of your buses gathered in all the different movelists you need, looking at all of your buses in one screen is only one tap away! Now you can safely move towards the bus stop that you know will have a bus that comes fastest, as compared to all the other bus stops, without having to flip back and forth between different bus stops or having to sieve those buses across confusingly named bus stops!</p>

<h2 id="a-final-word">A final word</h2>
<p>This iOS app is coded entirely in Swift. There were many more features I explored but ultimately could not implement due to unchangeable limitations. For example, I wanted to implement a widget that would show me live bus arrival timings within each particular movelist. Sadly, I discovered from <a href="https://developer.apple.com/documentation/widgetkit/keeping-a-widget-up-to-date">Apple documentation</a> that the daily refresh budget for a widget is around 40 to 70 times a day. Even at the maximum budget, this would imply a minimum 20 minute refresh rate which was simply untenable for buses whose frequencies were on the order of 10 minutes, and whose bus arrival times can change dramatically across the span of 10 minutes owing to evolving traffic conditions.</p>

<p>I am now moving towards publishing Instabus on the App Store!</p>]]></content><author><name></name></author><category term="blog" /><category term="jekyll" /><summary type="html"><![CDATA[Singapore has excellent public transport, but sometimes too much of a good thing can create a few relatively bad options. What do I mean?]]></summary></entry><entry><title type="html">Behind SKIM: LLM-powered Contract AI</title><link href="http://localhost:4000/blog/jekyll/2024/01/14/skim.html" rel="alternate" type="text/html" title="Behind SKIM: LLM-powered Contract AI" /><published>2024-01-14T00:00:00+08:00</published><updated>2024-01-14T00:00:00+08:00</updated><id>http://localhost:4000/blog/jekyll/2024/01/14/skim</id><content type="html" xml:base="http://localhost:4000/blog/jekyll/2024/01/14/skim.html"><![CDATA[<p>In this app, I wanted to simplify a key step of the contract review process that many lawyers may have to go through - that is, sifting through the boilerplate in order to establish exactly what obligations are being established between both parties to a contract. You can try it out <a href="https://skim-react.vercel.app">here</a> - if you are using it for the first time, do wait a little bit for the API to warm up; I‚Äôm working on a college student‚Äôs budget right now ):</p>

<p><img src="/assets/skim-1.gif" alt="The app in a nutshell" />
<em>Put in any contract text in the text box, or as a word document‚Ä¶</em></p>

<p><img src="/assets/skim-2.gif" alt="filter" />
<em>Easily filter for the obligation category you are interested in</em></p>

<p>This seems like a task right up the alley of artificial intelligence - especially with the latest advancements in natural language processing in the form of large language models! In order to do that, I needed to first establish the key elements of the app that I was going to code up. It would have to take any length of not-necessarily-well-structured text, and be able to detect obligations, then classify them into a pre-defined set of categories that frequently appear across most contracts. These problems are not easy at all, and if you chunk them into their constitutent steps, each would comprise a significant amount of inference that would not have been possible until recently.</p>

<p>So, in this blog post, I will explain each major step of the app, showing what happens under the hood, and why I made the design/engineering choice that I did. Enjoy!</p>

<h2 id="text-classification-via-large-language-models-the-core-of-this-app">Text classification via large language models: the core of this app</h2>

<p>The core problem of this app was essentially multi-label classification - that is, if I looked at a sentence, I would need to bin it into one of these categories:</p>

<ol>
  <li>Termination condition</li>
  <li>Performance obligation</li>
  <li>Payment obligation</li>
  <li>Compliance obligation</li>
  <li>Support or warranty obligation</li>
  <li>Insurance obligation</li>
  <li>Quality obligation</li>
  <li>Audit obligation</li>
  <li>Contract renewal</li>
  <li>Exceptions or exemptions</li>
  <li>Indemnification</li>
  <li>Jurisdiction</li>
  <li>None of the above</li>
</ol>

<p>A huge problem with multi-label classification is that it‚Äôs difficult to be accurate - if we were to train this classifier in a more traditional way, we would not only need to have a lot of training data - we would need to have a lot of training data <em>for each label</em>. That can add up very quickly, and isn‚Äôt very easy for an independent programmer to do.</p>

<p>This is why large language models are so useful for this task - they are essentially an extended version of transfer learning, that is, using embeddings already trained on a massive corpus of the internet, and jumping off of <em>that</em> as the starting point for any further training. This is a process known as <strong>fine-tuning</strong>, and it has been really successful at allowing for training on few pieces of training data.</p>

<p>Before we train any further though, let‚Äôs see some of the capabilities of large language models - available for free, off the shelf at Hugging Face - at <em>zero-shot classification</em>. In order to do that, we convert large language model‚Äôs key functionality - text to text generation - and use prompt engineering in order to get specific, standardized answers that would be easy to parse within a backend, and thus coerce it into a text classification task. I tested this on Google‚Äôs <a href="https://huggingface.co/google/flan-t5-large">flan-t5-large</a>, and was using a GPU for inference:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">T5Tokenizer</span><span class="p">,</span> <span class="n">T5ForConditionalGeneration</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">T5Tokenizer</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="sh">"</span><span class="s">google/flan-t5-large</span><span class="sh">"</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">T5ForConditionalGeneration</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="sh">"</span><span class="s">google/flan-t5-large</span><span class="sh">"</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="sh">'</span><span class="s">cuda</span><span class="sh">'</span><span class="p">)</span> <span class="c1"># With GPU --&gt; .to('cuda')
</span>
<span class="sh">"</span><span class="s">It is expressly understood that Commerce may unilaterally cancel this Contract for Contractor‚Äôs refusal to comply with this provision.</span><span class="sh">"</span>

<span class="n">input_prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"""</span><span class="s">
    Identify the clause type. If it is none, reply None

    Text: </span><span class="sh">"</span><span class="si">{</span><span class="n">clause_text</span><span class="si">}</span><span class="sh">"</span><span class="s">

    Contractual clause types:
    1. Termination condition
    2. Performance obligation
    3. Payment obligation
    4. Compliance obligation
    5. Support or warranty obligation
    6. Insurance obligation
    7. Quality obligation
    8. Audit obligation
    9. Contract renewal
    10. Exceptions or exemptions
    11. Indemnification
    12. Jurisdiction
    </span><span class="sh">"""</span>

<span class="n">input_ids</span> <span class="o">=</span> <span class="nf">tokenizer</span><span class="p">(</span><span class="n">input_prompt</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="sh">"</span><span class="s">pt</span><span class="sh">"</span><span class="p">).</span><span class="n">input_ids</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="sh">"</span><span class="s">cuda</span><span class="sh">"</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>
<span class="n">category</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="nf">decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="n">category</span><span class="p">)</span>
<span class="sh">"</span><span class="s">&lt;pad&gt; 1. &lt;/s&gt;</span><span class="sh">"</span>
</code></pre></div></div>

<p>Okay, that‚Äôs not too bad! It overall does a really great job at making predictions with zero prior information (provided by me) - but after looking at a full contract being processed there were two issues that stood out to me:</p>

<p>(1) there are a few clauses which are classified wrongly, and
(2) the answers are being returned in a format that I think is wrong (I want it to be returned as the text, not numbers)</p>

<p>It‚Äôs honestly really impressive that we‚Äôve gotten this far without really needing code (well - we needed code to download the model, but up till this point you could really just have used ChatGPT) - but the work awaits! Let‚Äôs fine-tune!</p>

<p>I get the zero-shot classifications and re-classify them by hand (for example, in the text I predicted earlier, I would write ‚ÄúTermination condition‚Äù as the desired output), and then I put that back in for fine-tuning:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="kn">import</span> <span class="n">json</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">torch</span>

<span class="kn">from</span> <span class="n">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span><span class="p">,</span> <span class="n">load_metric</span><span class="p">,</span> <span class="n">DatasetDict</span>

<span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">T5Tokenizer</span>

<span class="n">zs</span> <span class="o">=</span> <span class="nf">load_dataset</span><span class="p">(</span><span class="sh">'</span><span class="s">csv</span><span class="sh">'</span><span class="p">,</span> <span class="n">data_files</span><span class="o">=</span><span class="sh">'</span><span class="s">zeroshot.csv</span><span class="sh">'</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="sh">"</span><span class="s">train</span><span class="sh">"</span><span class="p">)</span>
<span class="c1"># 90% train, 10% test + validation
</span><span class="n">train_testvalid</span> <span class="o">=</span> <span class="n">zs</span><span class="p">.</span><span class="nf">train_test_split</span><span class="p">(</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="c1"># Split the 10% test + valid in half test, half valid
</span><span class="n">test_valid</span> <span class="o">=</span> <span class="n">train_testvalid</span><span class="p">[</span><span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">].</span><span class="nf">train_test_split</span><span class="p">(</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="c1"># gather everyone if you want to have a single DatasetDict
</span><span class="n">zs</span> <span class="o">=</span> <span class="nc">DatasetDict</span><span class="p">({</span>
    <span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">:</span> <span class="n">train_testvalid</span><span class="p">[</span><span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">:</span> <span class="n">test_valid</span><span class="p">[</span><span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">valid</span><span class="sh">'</span><span class="p">:</span> <span class="n">test_valid</span><span class="p">[</span><span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">]})</span>



<span class="n">model_checkpoint</span> <span class="o">=</span> <span class="sh">'</span><span class="s">google/flan-t5-large</span><span class="sh">'</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">T5Tokenizer</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>
<span class="n">max_input_length</span> <span class="o">=</span> <span class="mi">512</span> <span class="c1"># change to setting later
</span><span class="n">max_target_length</span> <span class="o">=</span> <span class="mi">512</span> <span class="c1"># change to setting later
</span>

<span class="k">def</span> <span class="nf">preprocess_data</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>

  <span class="n">inputs</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="k">for</span> <span class="n">clause_text</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">[</span><span class="sh">'</span><span class="s">clause</span><span class="sh">'</span><span class="p">]:</span>
    
    <span class="n">input_prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"""</span><span class="s">
        Identify the clause type. If it is none, reply None.

        Text: </span><span class="sh">"</span><span class="si">{</span><span class="n">clause_text</span><span class="si">}</span><span class="sh">"</span><span class="s">

        Contractual clause types:
        1. Termination condition
        2. Performance obligation
        3. Payment obligation
        4. Compliance obligation
        5. Support or warranty obligation
        6. Insurance obligation
        7. Quality obligation
        8. Audit obligation
        9. Contract renewal
        10. Exceptions or exemptions
        11. Indemnification
        12. Jurisdiction
        </span><span class="sh">"""</span>
    
    <span class="n">inputs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">input_prompt</span><span class="p">)</span>

  <span class="n">model_inputs</span> <span class="o">=</span> <span class="nf">tokenizer</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_input_length</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

  <span class="c1"># Setup the tokenizer for targets
</span>  <span class="k">with</span> <span class="n">tokenizer</span><span class="p">.</span><span class="nf">as_target_tokenizer</span><span class="p">():</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="nf">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="sh">"</span><span class="s">flan_fewshot_cat</span><span class="sh">"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_target_length</span><span class="p">,</span> 
                       <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

  <span class="n">model_inputs</span><span class="p">[</span><span class="sh">"</span><span class="s">labels</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="sh">"</span><span class="s">input_ids</span><span class="sh">"</span><span class="p">]</span>
  <span class="k">return</span> <span class="n">model_inputs</span>

<span class="n">tokenized_datasets</span> <span class="o">=</span> <span class="n">zs</span><span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="n">preprocess_data</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForSeq2SeqLM</span><span class="p">,</span> <span class="n">DataCollatorForSeq2Seq</span><span class="p">,</span> <span class="n">Seq2SeqTrainingArguments</span><span class="p">,</span> <span class="n">Seq2SeqTrainer</span>

<span class="n">model_name</span> <span class="o">=</span> <span class="sh">"</span><span class="s">flan-t5-large-skim</span><span class="sh">"</span>
<span class="n">model_dir</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">bigdata/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="sh">"</span>

<span class="n">args</span> <span class="o">=</span> <span class="nc">Seq2SeqTrainingArguments</span><span class="p">(</span>
    <span class="n">model_dir</span><span class="p">,</span>
    <span class="n">evaluation_strategy</span><span class="o">=</span><span class="sh">"</span><span class="s">steps</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">eval_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">logging_strategy</span><span class="o">=</span><span class="sh">"</span><span class="s">steps</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">logging_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">save_strategy</span><span class="o">=</span><span class="sh">"</span><span class="s">steps</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">save_steps</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">4e-5</span><span class="p">,</span>
    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
    <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
    <span class="n">save_total_limit</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">predict_with_generate</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">fp16</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">metric_for_best_model</span><span class="o">=</span><span class="sh">"</span><span class="s">rouge1</span><span class="sh">"</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">data_collator</span> <span class="o">=</span> <span class="nc">DataCollatorForSeq2Seq</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">)</span>


<span class="c1"># Function that returns an untrained model to be trained
</span><span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">T5Tokenizer</span><span class="p">,</span> <span class="n">T5ForConditionalGeneration</span>
<span class="k">def</span> <span class="nf">model_init</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">T5ForConditionalGeneration</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>


<span class="n">trainer</span> <span class="o">=</span> <span class="nc">Seq2SeqTrainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="nf">model_init</span><span class="p">(),</span>
    <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">tokenized_datasets</span><span class="p">[</span><span class="sh">"</span><span class="s">train</span><span class="sh">"</span><span class="p">],</span>
    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">tokenized_datasets</span><span class="p">[</span><span class="sh">"</span><span class="s">valid</span><span class="sh">"</span><span class="p">],</span>
    <span class="n">data_collator</span><span class="o">=</span><span class="n">data_collator</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">trainer</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
</code></pre></div></div>

<p>In order to save my work, I save it locally, and also push it to the Hugging Face Hub.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">trainer</span><span class="p">.</span><span class="nf">save_model</span><span class="p">(</span><span class="sh">"</span><span class="s">bigdata/flan-t5-large-skim</span><span class="sh">"</span><span class="p">)</span> <span class="c1"># save model locally
</span><span class="n">trainer</span><span class="p">.</span><span class="nf">push_to_hub</span><span class="p">()</span> <span class="c1"># push to hugging face hub
</span></code></pre></div></div>

<p>The great thing about pushing it to the Hugging Face Hub is that they have a free inference API that allows you to host the computationally-heavy process on their servers instead of spinning up a server with enough RAM to fit large language models! The only issue is that there are rate limits, and they are not very forthcoming about the explicit limits‚Ä¶</p>

<h2 id="text-preprocessing">Text preprocessing</h2>

<p>Awesome! Now that we have our language model, surely we are done! Not so fast - a key step in designing apps is to understand the way in which your users will interact with your app. If I were a tired lawyer, I would not want to paste my obligations in one by one to check! That is why I designed my app to handle either long-form text being submitted through a text box, or even just a word document. Let‚Äôs take a look at some of the code that begins by parsing a word document:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c1"># Extract text from the .docx file
</span><span class="n">doc</span> <span class="o">=</span> <span class="nc">Document</span><span class="p">(</span><span class="n">docx_stream</span><span class="p">)</span>
<span class="n">clause_text</span> <span class="o">=</span> <span class="sh">""</span>

<span class="k">for</span> <span class="n">paragraph</span> <span class="ow">in</span> <span class="n">doc</span><span class="p">.</span><span class="n">paragraphs</span><span class="p">:</span>
    <span class="n">clause_text</span> <span class="o">+=</span> <span class="n">paragraph</span><span class="p">.</span><span class="n">text</span> <span class="o">+</span> <span class="sh">"</span><span class="se">\n</span><span class="sh">"</span>
</code></pre></div></div>

<p>Now, because text can be very unstructured (even if very readable!), I need to take a few text preprocessing steps in order to make sure my model isn‚Äôt inferring on garbage: empty strings, accidentally captured metadata, page numbers.</p>

<p>And before that, an even more important step: if you have noticed, my model presumes that I am sending in a single, complete sentence. That means that paragraphs will have to be broken up into sentences. This presents many problems, since rule-based methods, like splitting on periods, may end up accidentally catching periods within sentences (for example, decimal places/systems).</p>

<p>To solve this problem, I use <code class="language-plaintext highlighter-rouge">spacy</code>‚Äôs sentence boundary detection, which in turn uses dependency parsing to propagate from roots (eg. subject, object) down through their children (eg. adjectives, adverbs), till the end, which is then determined as a sentence boundary.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">spacy</span>

<span class="kn">from</span> <span class="n">spacy.cli</span> <span class="kn">import</span> <span class="n">download</span>

<span class="c1"># Specify the model name
</span><span class="n">model_name</span> <span class="o">=</span> <span class="sh">'</span><span class="s">en_core_web_sm</span><span class="sh">'</span>

<span class="c1"># Check if the model is already installed
</span><span class="k">if</span> <span class="n">model_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">spacy</span><span class="p">.</span><span class="n">util</span><span class="p">.</span><span class="nf">get_installed_models</span><span class="p">():</span>
    <span class="c1"># If not installed, download the model
</span>    <span class="nf">download</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>

<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">split_into_sentences</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">sentences</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="nf">nlp</span><span class="p">(</span><span class="n">text</span><span class="p">).</span><span class="n">sents</span><span class="p">)</span>
    <span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="n">sentence</span><span class="p">.</span><span class="n">text</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">sentences</span>
</code></pre></div></div>

<p>Let‚Äôs see how this sentence boundary detection works with a tricky sentence.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">text</span> <span class="o">=</span> <span class="sa">r</span><span class="sh">"</span><span class="s">Contractor shall allow public access to all documents, papers, letters or other materials made or received by Contractor in conjunction with this Contract, unless the records are exempt from section 24(a) of Article I of the State Constitution and section 119.07(1), F.S.  It is expressly understood that Commerce may unilaterally cancel this Contract for Contractor‚Äôs refusal to comply with this provision.</span><span class="sh">"</span>
<span class="o">&gt;&gt;&gt;</span> <span class="p">[</span><span class="n">text</span><span class="p">.</span><span class="n">text</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="nf">list</span><span class="p">(</span><span class="nf">nlp</span><span class="p">(</span><span class="n">text</span><span class="p">).</span><span class="n">sents</span><span class="p">)]</span>

<span class="p">[</span><span class="sh">'</span><span class="s">Contractor shall allow public access to all documents, papers, letters or other materials made or received by Contractor in conjunction with this Contract, unless the records are exempt from section 24(a) of Article I of the State Constitution and section 119.07(1), F.S.  </span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">It is expressly understood that Commerce may unilaterally cancel this Contract for Contractor‚Äôs refusal to comply with this provision.</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div>

<p>Great! Another major thing that I do is to strip out accidentally captured metadata, say if ‚ÄúPage 1 of 24‚Äù or ‚ÄúPage 2 of 24‚Äù or headers/footers accidentally make their way into the word document. In order to do this, I check if pairwise cosine similarities are above a particular threshold:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>
<span class="kn">from</span> <span class="n">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_distances</span>
<span class="kn">from</span> <span class="n">itertools</span> <span class="kn">import</span> <span class="n">combinations</span>


<span class="k">def</span> <span class="nf">remove_repetitive_strings</span><span class="p">(</span><span class="n">strings</span><span class="p">,</span> <span class="n">similarity_threshold</span><span class="o">=</span><span class="mi">80</span><span class="p">):</span>
    <span class="c1"># Use TF-IDF Vectorizer to embed each line as a vector
</span>    <span class="n">vectorizer</span> <span class="o">=</span> <span class="nc">TfidfVectorizer</span><span class="p">()</span>
    <span class="n">vectors</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">strings</span><span class="p">)</span>

    <span class="c1"># Calculate pairwise cosine distances
</span>    <span class="n">distances</span> <span class="o">=</span> <span class="nf">cosine_distances</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>

    <span class="c1"># Identify pairs with similarity below the threshold
</span>    <span class="n">filtered_pairs</span> <span class="o">=</span> <span class="p">[(</span><span class="n">strings</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">strings</span><span class="p">[</span><span class="n">j</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">combinations</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">strings</span><span class="p">)),</span> <span class="mi">2</span><span class="p">)</span>
                      <span class="k">if</span> <span class="n">distances</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">similarity_threshold</span> <span class="o">/</span> <span class="mi">100</span><span class="p">)]</span>

    <span class="c1"># Create a set of strings to keep track of unique strings
</span>    <span class="n">unique_strings</span> <span class="o">=</span> <span class="nf">set</span><span class="p">()</span>

    <span class="c1"># Add strings from filtered pairs to unique_strings
</span>    <span class="k">for</span> <span class="n">string1</span><span class="p">,</span> <span class="n">string2</span> <span class="ow">in</span> <span class="n">filtered_pairs</span><span class="p">:</span>
        <span class="n">unique_strings</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="n">string1</span><span class="p">)</span>
        <span class="n">unique_strings</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="n">string2</span><span class="p">)</span>

    <span class="c1"># Filter the original list based on unique strings
</span>    <span class="n">filtered_strings</span> <span class="o">=</span> <span class="p">[</span><span class="n">string</span> <span class="k">for</span> <span class="n">string</span> <span class="ow">in</span> <span class="n">strings</span> <span class="k">if</span> <span class="n">string</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">unique_strings</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">filtered_strings</span>
</code></pre></div></div>

<p>There are some other basic things that I do, like stripping whitespaces or removing strings that don‚Äôt have any alphabetical content.</p>

<h2 id="front-end-to-back-end-an-overall-structure">Front-end to back-end: an overall structure</h2>

<p>The overall structure of the app is as follows: I run one instance of a ReactJS front-end on Vercel, and another instance of a Flask back-end on Azure. The Flask back-end handles all the text pre-processing and inference, whereas the ReactJS front-end passes text entered by the user on the web through a POST request towards the back-end, and receives the text.</p>

<p>There are many little details in the React app - like hovering over a clause text also highlights all other clause texts in the same category, and hovering over the category text at the top also highlights clause texts in that category, as well as other features like dynamically re-sizing text boxes. But there was one feature that was an interesting problem took a while to handle, and that was streaming.</p>

<p>You see, even the best large language models like ChatGPT take a while to complete inference. From the user‚Äôs standpoint, the total time of inference might be unacceptable, but they might be more willing to accept small chunks of the text being additively processed.</p>

<p>Therefore, in my use case, instead of waiting for the whole list of texts to be processed, I stream information back from the Flask app at every step of the loop using <code class="language-plaintext highlighter-rouge">yield</code>, and React is capable of processing this data while <code class="language-plaintext highlighter-rouge">await</code>ing the final set of data:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Flask side:
</span><span class="nd">@app.route</span><span class="p">(</span><span class="sh">'</span><span class="s">/api/generate_clause</span><span class="sh">'</span><span class="p">,</span> <span class="n">methods</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">POST</span><span class="sh">'</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">generate_clause</span><span class="p">():</span>

    <span class="k">def</span> <span class="nf">generate</span><span class="p">():</span>
        <span class="n">progress</span><span class="o">=</span><span class="mi">0</span>
        <span class="n">clause_text</span> <span class="o">=</span> <span class="n">request</span><span class="p">.</span><span class="n">json</span><span class="p">[</span><span class="sh">'</span><span class="s">text</span><span class="sh">'</span><span class="p">]</span>

        <span class="n">lotexts</span> <span class="o">=</span> <span class="nf">splitter</span><span class="p">(</span><span class="n">clause_text</span><span class="p">)</span> <span class="c1"># splits text according to preprocessing rules
</span>
        <span class="sh">"""</span><span class="s">
        Takes in a list of texts (lotexts) that has already been processed. could be a word doc file or just simple text, either way, they just need to be in an orderly list of texts.
        </span><span class="sh">"""</span>
        <span class="n">lodict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">text</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">lotexts</span><span class="p">):</span>
            <span class="n">progress</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="nf">len</span><span class="p">(</span><span class="n">lotexts</span><span class="p">)</span>

            <span class="n">input_prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"""</span><span class="s">
            Identify the clause type. If it is none, reply None

            Text: </span><span class="sh">"</span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="sh">"</span><span class="s">

            Contractual clause types:
            1. Termination condition
            2. Performance obligation
            3. Payment obligation
            4. Compliance obligation
            5. Support or warranty obligation
            6. Insurance obligation
            7. Quality obligation
            8. Audit obligation
            9. Contract renewal
            10. Exceptions or exemptions
            11. Indemnification
            12. Jurisdiction
            </span><span class="sh">"""</span>

            <span class="c1"># error handling for model initialization
</span>            <span class="n">output</span> <span class="o">=</span> <span class="nf">query</span><span class="p">({</span>
                <span class="sh">"</span><span class="s">inputs</span><span class="sh">"</span><span class="p">:</span> <span class="n">input_prompt</span><span class="p">,</span> <span class="sh">"</span><span class="s">wait_for_model</span><span class="sh">"</span><span class="p">:</span> <span class="bp">True</span>
            <span class="p">})</span>

            <span class="n">category</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="sh">'</span><span class="s">generated_text</span><span class="sh">'</span><span class="p">]</span>

            <span class="n">lodict</span><span class="p">.</span><span class="nf">update</span><span class="p">({</span><span class="n">text</span><span class="p">:</span> <span class="n">category</span><span class="p">})</span>

            <span class="n">json_data</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">text_block</span><span class="sh">'</span><span class="p">:</span> <span class="n">clause_text</span><span class="p">,</span> <span class="sh">'</span><span class="s">lookup</span><span class="sh">'</span><span class="p">:</span> <span class="n">lodict</span><span class="p">,</span> <span class="sh">'</span><span class="s">progress</span><span class="sh">'</span><span class="p">:</span> <span class="n">progress</span><span class="p">}</span>
            <span class="n">json_string</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="nf">dumps</span><span class="p">(</span><span class="n">json_data</span><span class="p">)</span>

            <span class="k">yield</span> <span class="n">json_string</span>  <span class="c1"># Add a special object to separate JSON streamed objects
</span>
    <span class="c1"># Use Response and stream_with_context to handle streaming
</span>    <span class="k">return</span> <span class="nc">Response</span><span class="p">(</span><span class="nf">stream_with_context</span><span class="p">(</span><span class="nf">generate</span><span class="p">()),</span>
                    <span class="n">content_type</span><span class="o">=</span><span class="sh">'</span><span class="s">text/event-stream</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="err">#</span> <span class="nx">React</span> <span class="nx">side</span>

<span class="kd">const</span> <span class="p">[</span><span class="nx">outputText</span><span class="p">,</span> <span class="nx">setOutputText</span><span class="p">]</span> <span class="o">=</span> <span class="nf">useState</span><span class="p">(</span><span class="dl">''</span><span class="p">);</span> <span class="c1">//text just gives the raw block text to be displayed</span>
<span class="kd">const</span> <span class="p">[</span><span class="nx">outputData</span><span class="p">,</span> <span class="nx">setOutputData</span><span class="p">]</span> <span class="o">=</span> <span class="nf">useState</span><span class="p">({})</span>
<span class="kd">const</span> <span class="p">[</span><span class="nx">progress</span><span class="p">,</span> <span class="nx">setProgress</span><span class="p">]</span> <span class="o">=</span> <span class="nf">useState</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>

<span class="kd">const</span> <span class="nx">handleGenerateClick</span> <span class="o">=</span> <span class="k">async </span><span class="p">()</span> <span class="o">=&gt;</span> <span class="p">{</span>
    <span class="kd">const</span> <span class="nx">url</span> <span class="o">=</span> <span class="dl">'</span><span class="s1">http://localhost:5000/api/generate_clause</span><span class="dl">'</span><span class="p">;</span>
    <span class="kd">var</span> <span class="nx">tmpPromptResponse</span> <span class="o">=</span> <span class="dl">''</span><span class="p">;</span>
    <span class="k">try</span> <span class="p">{</span>
      <span class="kd">const</span> <span class="nx">response</span> <span class="o">=</span> <span class="k">await</span> <span class="nf">fetch</span><span class="p">(</span><span class="nx">url</span> <span class="p">,</span> <span class="p">{</span>
        <span class="na">method</span><span class="p">:</span> <span class="dl">'</span><span class="s1">POST</span><span class="dl">'</span><span class="p">,</span>
        <span class="na">headers</span><span class="p">:</span> <span class="p">{</span>
          <span class="dl">'</span><span class="s1">Content-Type</span><span class="dl">'</span><span class="p">:</span> <span class="dl">'</span><span class="s1">application/json</span><span class="dl">'</span>
        <span class="p">},</span>
        <span class="na">body</span><span class="p">:</span> <span class="nx">JSON</span><span class="p">.</span><span class="nf">stringify</span><span class="p">({</span>
          <span class="na">text</span><span class="p">:</span> <span class="nx">inputText</span><span class="p">,</span>
        <span class="p">}),</span>
      <span class="p">});</span>
      
      <span class="c1">// eslint-disable-next-line no-undef</span>
      <span class="kd">let</span> <span class="nx">decoder</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">TextDecoderStream</span><span class="p">();</span>
      <span class="k">if </span><span class="p">(</span><span class="o">!</span><span class="nx">response</span><span class="p">.</span><span class="nx">body</span><span class="p">)</span> <span class="k">return</span><span class="p">;</span>
      <span class="kd">const</span> <span class="nx">reader</span> <span class="o">=</span> <span class="nx">response</span><span class="p">.</span><span class="nx">body</span>
        <span class="p">.</span><span class="nf">pipeThrough</span><span class="p">(</span><span class="nx">decoder</span><span class="p">)</span>
        <span class="p">.</span><span class="nf">getReader</span><span class="p">();</span>
      
      <span class="k">while </span><span class="p">(</span><span class="kc">true</span><span class="p">)</span> <span class="p">{</span>
        <span class="kd">var</span> <span class="p">{</span><span class="nx">value</span><span class="p">,</span> <span class="nx">done</span><span class="p">}</span> <span class="o">=</span> <span class="k">await</span> <span class="nx">reader</span><span class="p">.</span><span class="nf">read</span><span class="p">();</span>
        
        <span class="k">if </span><span class="p">(</span><span class="nx">done</span><span class="p">)</span> <span class="p">{</span>
          <span class="k">break</span><span class="p">;</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
          <span class="nx">tmpPromptResponse</span> <span class="o">=</span> <span class="nx">JSON</span><span class="p">.</span><span class="nf">parse</span><span class="p">(</span><span class="nx">value</span><span class="p">);</span>
          <span class="nf">setOutputText</span><span class="p">(</span><span class="nx">tmpPromptResponse</span><span class="p">.</span><span class="nx">text_block</span><span class="p">);</span>
          <span class="nf">setOutputData</span><span class="p">(</span><span class="nx">tmpPromptResponse</span><span class="p">.</span><span class="nx">lookup</span><span class="p">);</span>
          <span class="nf">setProgress</span><span class="p">(</span><span class="nx">tmpPromptResponse</span><span class="p">.</span><span class="nx">progress</span><span class="p">);</span>

        <span class="p">}</span>
      <span class="p">}</span>
    <span class="p">}</span> <span class="k">catch </span><span class="p">(</span><span class="nx">error</span><span class="p">)</span> <span class="p">{</span>
      <span class="nx">console</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="nx">error</span><span class="p">);</span>
    <span class="p">}</span>

  <span class="p">};</span>

</code></pre></div></div>

<h2 id="a-final-word">A final word</h2>

<p>That brings me to the end of this blog! I think it was a pretty good experience handling everything from conceptualization, down to specifying a language model, testing and finetuning it, before setting it up on a Flask back-end server, and then designing a very preliminary user experience on a React front-end, and finally considering how all the moving pieces would fit together within a production context with compute power constraints (well, in my case, <em>severe</em> constraints).</p>

<p>A lot of what I could do on my GPU-enabled development run was rendered moot because of production constraints: for example, without using Hugging Face‚Äôs inference API, I could categorize documents a lot faster and without any limits. But we all must accept and work within the constraints provided, and this project was very instructive in the details of the full production process of an AI project.</p>]]></content><author><name></name></author><category term="blog" /><category term="jekyll" /><summary type="html"><![CDATA[In this app, I wanted to simplify a key step of the contract review process that many lawyers may have to go through - that is, sifting through the boilerplate in order to establish exactly what obligations are being established between both parties to a contract. You can try it out here - if you are using it for the first time, do wait a little bit for the API to warm up; I‚Äôm working on a college student‚Äôs budget right now ):]]></summary></entry><entry><title type="html">Optimal control, trajectory optimization, and getting a rocket to space</title><link href="http://localhost:4000/blog/jekyll/2024/01/12/rockets.html" rel="alternate" type="text/html" title="Optimal control, trajectory optimization, and getting a rocket to space" /><published>2024-01-12T00:00:00+08:00</published><updated>2024-01-12T00:00:00+08:00</updated><id>http://localhost:4000/blog/jekyll/2024/01/12/rockets</id><content type="html" xml:base="http://localhost:4000/blog/jekyll/2024/01/12/rockets.html"><![CDATA[<p>Let‚Äôs say we wanted to get a rocket to orbit - based on experience (or, if you‚Äôve made it through the Kerbal Space Program tutorial like me), you would roughly know that, with the rocket starting at an upward attitude with respect to the center of the Earth, you would want it to gradually tilt over to become increasingly parallel to the surface of the Earth. But what if we wanted to optimize some part of this flight process - let‚Äôs say, to make sure that we have as much fuel mass left as possible at the end of the journey? Well, the next thing we‚Äôd think about it, what are the factors of the flight that we can control, and how do these controls, on a physical basis, affect the state of the rocket (eg. the position of the rocket, the velocity of the rocket, the mass of the rocket)?</p>

<p>The simplest reducible example that we can think of is a car at rest at a starting position, which we want to get to a final position, also at rest. We specify an objective - for example, that we want it to reach its final position in the shortest possible time - and then ask what series of controls (applied forces) would optimize that objective. Intuitively, we would say - apply the maximum amount of force possible to get it to accelerate, before the applying the maximum amount of force possible in the opposite direction to get it to decelerate - and indeed, <a href="https://en.wikipedia.org/wiki/Bang%E2%80%93bang_control">bang-bang solutions</a> are an optimal control.</p>

<p>There are a few special cases where analytical solutions can be found, but most don‚Äôt. This brings us to the field of numerical methods to approximate optimal control solutions - one of which is known as trajectory optimization!</p>

<p>In this app, I display the optimal control trajectory, given a starting position and final desired orbital parameters, using an algorithm known as trajectory optimization. You can try it <a href="https://rocket-optimal-control.streamlit.app/">here</a>.</p>

<p><img src="/assets/rocket.gif" alt="The app in a nutshell" /></p>

<h2 id="mathy-stuff-if-you-like-it">Mathy stuff if you like it</h2>

<p>In this section, I outline the optimal control problem specifically:</p>

<p><img src="/assets/optimalcontrol-1.png" alt="" />
<img src="/assets/optimalcontrol-2.png" alt="" />
<img src="/assets/optimalcontrol-3.png" alt="" /></p>]]></content><author><name></name></author><category term="blog" /><category term="jekyll" /><summary type="html"><![CDATA[Let‚Äôs say we wanted to get a rocket to orbit - based on experience (or, if you‚Äôve made it through the Kerbal Space Program tutorial like me), you would roughly know that, with the rocket starting at an upward attitude with respect to the center of the Earth, you would want it to gradually tilt over to become increasingly parallel to the surface of the Earth. But what if we wanted to optimize some part of this flight process - let‚Äôs say, to make sure that we have as much fuel mass left as possible at the end of the journey? Well, the next thing we‚Äôd think about it, what are the factors of the flight that we can control, and how do these controls, on a physical basis, affect the state of the rocket (eg. the position of the rocket, the velocity of the rocket, the mass of the rocket)?]]></summary></entry></feed>